\section{Literature Review}

The question of accurate energy profiling for \gls{CPU}s and other components
of a computational system has attracted substantial attention in both
academic and industrial communities. Prior work can be grouped into:
\begin{itemize}
  \item Studies that validate and quantify characteristics of
    software-accessible counters (e.g. \gls{RAPL} and analogous interfaces).
  \item Comparisons between software and external/hardware meters.
  \item Methodical works on measurement protocols, reproducibility and energy
    accounting in \gls{HPC} contexts.
\end{itemize}

Several recent comparative and methodological studies focus on software
exposure mechanisms such as \gls{RAPL} and their operational caveats.
\textcite{SoftMeasComp} provide a broad comparative analysis of
software-based \gls{CPU} energy measurement techniques and discuss OS
integration issues and practical limitations of \gls{RAPL}. Similarly,
\textcite{RAPL_Strategies} focus on practical strategies to employ
\gls{RAPL} in \gls{HPC} workflows and discuss measurement placement and
workflow integration. While these works are valuable, the majority of existing
comparative literature still places \gls{RAPL} at the center of the analysis,
leaving vendor-specific telemetry mechanisms (e.g. AMD \gls{SMU} / \gls{PM}
tables) less explored.

From a systems and instrumentation perspective, several peer-reviewed
works provide rigorous approaches to per-core and per-package accounting
and discuss pitfalls that are directly relevant for this thesis. The
E-Team project introduced a practical energy accounting methodology for
multi-core systems and demonstrates architectural and measurement
techniques to obtain process- and core-level energy attribution in
realistic workloads \parencite{ETeam_2017}. Such methods are relevant
when comparing aggregated \gls{RAPL} readings (which are often package-level)
against finer-grained telemetry exposed by vendor-specific interfaces.

For accelerators and \gls{GPU}s, studies show that software interfaces (for
example, vendor telemetry APIs) must be validated against external
power meters and that measurement methodology materially affects
results and reproducibility \parencite{You_2023_Zeus}. These findings
underscore the need for careful experimental design (sampling period,
synchronization, and bias analysis) when juxtaposing telemetry sources
with different semantics (power vs.\ energy, instantaneous vs.\
cumulative counters).

There is also a body of work addressing repeatability and the
environmental / carbon accounting of computation. For example,
\textcite{GreenAlgos} propose standardized reporting practices
for computational carbon footprints and emphasize traceable,
reproducible measurements and reporting; such guidelines inform the
methodological choices in this study (sampling, metadata recording,
machine specification capture).

Taken together, the extant literature motivates three conclusions that
inform this work's design:

\begin{enumerate}
  \item \gls{RAPL} is well-studied and widely used, but has documented limits
    of power domains ambiguity, register overflows, and aggregation issues
    that motivate validation against alternative telemetry sources.
  \item Vendor-native telemetry (AMD \gls{SMU} / \gls{PM} tables) is promising
    but underrepresented in comparative, peer-reviewed studies, which makes
    careful validation of the chosen methodological approaches essential.
  \item Reproducible experimental methodology, that leverages clear metadata,
    regular re-sampling, overflow handling and statistical tests, is essential
    to produce defensible comparisons.
\end{enumerate}

This thesis builds on the published methods and gaps above: the core goal is
to provide a systematic, statistically grounded comparison of \gls{RAPL} and
AMD-native telemetry (\gls{SMU} / \gls{PM} tables) on AMD \gls{CPU}s, closing 
a documented gap in the literature by:

\begin{itemize}
  \item Instrumenting both sources simultaneously.
  \item Using a robust re-sampling and overflow-aware pipeline.
  \item Applying agreement analyses to quantify differences.
\end{itemize}
